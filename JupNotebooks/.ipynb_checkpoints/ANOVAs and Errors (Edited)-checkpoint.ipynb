{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Part II\n",
    "\n",
    "In Linear Regression Part I, we did a brief overview of the output of a regression in statsmodels. Now we'll take a more in-depth look at outputs. \n",
    "\n",
    "First load our libraries and our data, the [same as from last lesson](https://drive.google.com/open?id=19NgWK34NK5fGCA2eU4rDJ_Fo45nnQIi_):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.regression import linear_model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "dfm = pd.read_csv('data/MLR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marketing Budget</th>\n",
       "      <th>Website Visits</th>\n",
       "      <th>Number of Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marketing Budget  Website Visits  Number of Sales\n",
       "0               0.5             0.5                1\n",
       "1               0.5             1.3                0\n",
       "2               0.3             0.2                2\n",
       "3               0.3             0.7                5\n",
       "4               0.4             0.6                5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this we need to add our intercept, and fit the regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.986</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.986</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6983.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 28 Jan 2019</td> <th>  Prob (F-statistic):</th> <td>5.05e-180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:36:28</td>     <th>  Log-Likelihood:    </th> <td> -610.95</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   195</td>      <th>  AIC:               </th> <td>   1228.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   192</td>      <th>  BIC:               </th> <td>   1238.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0982</td> <td>    0.839</td> <td>    0.117</td> <td> 0.907</td> <td>   -1.557</td> <td>    1.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    3.6367</td> <td>    0.593</td> <td>    6.137</td> <td> 0.000</td> <td>    2.468</td> <td>    4.805</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    6.5617</td> <td>    0.302</td> <td>   21.701</td> <td> 0.000</td> <td>    5.965</td> <td>    7.158</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.065</td> <th>  Durbin-Watson:     </th> <td>   1.768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.587</td> <th>  Jarque-Bera (JB):  </th> <td>   1.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.171</td> <th>  Prob(JB):          </th> <td>   0.566</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.847</td> <th>  Cond. No.          </th> <td>    27.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.986\n",
       "Model:                            OLS   Adj. R-squared:                  0.986\n",
       "Method:                 Least Squares   F-statistic:                     6983.\n",
       "Date:                Mon, 28 Jan 2019   Prob (F-statistic):          5.05e-180\n",
       "Time:                        11:36:28   Log-Likelihood:                -610.95\n",
       "No. Observations:                 195   AIC:                             1228.\n",
       "Df Residuals:                     192   BIC:                             1238.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0982      0.839      0.117      0.907      -1.557       1.753\n",
       "x1             3.6367      0.593      6.137      0.000       2.468       4.805\n",
       "x2             6.5617      0.302     21.701      0.000       5.965       7.158\n",
       "==============================================================================\n",
       "Omnibus:                        1.065   Durbin-Watson:                   1.768\n",
       "Prob(Omnibus):                  0.587   Jarque-Bera (JB):                1.139\n",
       "Skew:                           0.171   Prob(JB):                        0.566\n",
       "Kurtosis:                       2.847   Cond. No.                         27.9\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sm.add_constant(dfm[['Marketing Budget', 'Website Visits']].values)\n",
    "y = dfm['Number of Sales'].values\n",
    "model = sm.OLS(y,X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09823378052704296 3.636655497639606 6.561719834098829\n"
     ]
    }
   ],
   "source": [
    "#From the above mdoel, we may want to get rid of the coeff since we arent too sure if its actually zero\n",
    "\n",
    "#to access coeffis from model, use model.params\n",
    "beta_0, beta_1, beta_2 = model.params\n",
    "print(beta_0, beta_1, beta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can use our model to predict new sales on new data for mkt budget and num website visits.\n",
    "#We pass in list or array of [const., mkt budget, webvisits]. A const of 1 is making sure the beta_0 is \n",
    "#included when predicting numsales from 5 mkt budget and 5 numvists\n",
    "\n",
    "model.predict([1,5,5])\n",
    "#OR\n",
    "mkt_bud = 5\n",
    "web_vis = 5\n",
    "y_pred = beta_0 + beta_1*mkt_bud + beta_2*web_vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table gives us several interesting and more advances statistics about our regression.\n",
    "\n",
    "Our R squared is a measure of how much of the total variation in our data was explained by our model. In a model with a single independant variable, the $R^2$ is the square of the correlation coeeficient.\n",
    "\n",
    "In a more complicated model, it is useful to divide out the sources of variability in the data.\n",
    "\n",
    "The total sum of squares is the sum of the square distance of each dependant data point from the mean:\n",
    "\n",
    "$$ SS_{total} = \\sum\\limits_{i=1}^{n}(y_i - \\bar{y})^2 $$\n",
    "\n",
    "The explained sum of squares is the sum of the square differences between predicted and mean y values:\n",
    "\n",
    "$$ SS_{reg} = \\sum\\limits_{i=1}^{n}(f_i - \\bar{y})^2 $$\n",
    "\n",
    "The residual sum of squares:\n",
    "\n",
    "$$ SS_{res} = \\sum\\limits_{i=1}^{n}(y_i - f_i)^2 $$\n",
    "\n",
    "From these measures, we can calculate $R^2$:\n",
    "\n",
    "$$ R^2 = 1 - \\frac{SS_{res}}{SS_{total}} $$\n",
    "\n",
    "### Preventing Overfitting\n",
    "\n",
    "When creating multiple models we can use some of the statistics included to ensure that we do not overfit the data. \n",
    "\n",
    "Adjusted $R^2$ is the $R^2$ above, but it is adjusted for the number of parameters included in the model:\n",
    "\n",
    "$$ R_{adj}^2 = 1 - \\frac{n-1}{df_{resid}}(1-R^2)$$\n",
    "\n",
    "In our case, the number of observations, n, is large enough that our low number of variables does not seriously impact our R-Squared.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want a model with the highest R squared with the least amount of variables. \n",
    "#Adjusted R squared helps with that and will penalize you if you have more variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares Alternatives\n",
    "\n",
    "We have been running least squares regressions up until now, which simply minimizes the sum of squares of the errors.\n",
    "\n",
    "Recall, this has a form like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   67.73</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 28 Jan 2019</td> <th>  Prob (F-statistic):</th> <td>8.18e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:12:11</td>     <th>  Log-Likelihood:    </th> <td> -256.98</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   518.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   523.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    2.2378</td> <td>    0.319</td> <td>    7.005</td> <td> 0.000</td> <td>    1.604</td> <td>    2.872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    2.7449</td> <td>    0.334</td> <td>    8.230</td> <td> 0.000</td> <td>    2.083</td> <td>    3.407</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.974</td> <th>  Durbin-Watson:     </th> <td>   2.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.615</td> <th>  Jarque-Bera (JB):  </th> <td>   0.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.020</td> <th>  Prob(JB):          </th> <td>   0.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.528</td> <th>  Cond. No.          </th> <td>    1.05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.409\n",
       "Model:                            OLS   Adj. R-squared:                  0.403\n",
       "Method:                 Least Squares   F-statistic:                     67.73\n",
       "Date:                Mon, 28 Jan 2019   Prob (F-statistic):           8.18e-13\n",
       "Time:                        12:12:11   Log-Likelihood:                -256.98\n",
       "No. Observations:                 100   AIC:                             518.0\n",
       "Df Residuals:                      98   BIC:                             523.2\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.2378      0.319      7.005      0.000       1.604       2.872\n",
       "x1             2.7449      0.334      8.230      0.000       2.083       3.407\n",
       "==============================================================================\n",
       "Omnibus:                        0.974   Durbin-Watson:                   2.071\n",
       "Prob(Omnibus):                  0.615   Jarque-Bera (JB):                0.933\n",
       "Skew:                          -0.020   Prob(JB):                        0.627\n",
       "Kurtosis:                       2.528   Cond. No.                         1.05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# We'll randomly generate some data\n",
    "x = np.random.normal(size = 100)\n",
    "y = 3*x + 2 + np.random.normal(scale = 3, size = 100)\n",
    "\n",
    "# Remember, we have to add in the constant\n",
    "X = sm.add_constant(x)\n",
    "\n",
    "# Define our regression, fit our model\n",
    "my_reg = sm.OLS(y,X).fit()\n",
    "\n",
    "# Look at the summary\n",
    "my_reg.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the base for linear regression, however in recent years, people have been working on finding better alternatives.\n",
    "\n",
    "We often want to penalize large coefficients, or shrink them to 0, this is another method of reducing overfitting.\n",
    "\n",
    "In linear regression, we can add this step in by adding to the 'penalty' part of the least squares. Now, we can try to minimize the sum of squares, as well as an extra term.\n",
    "\n",
    "### L1 and L2 Norms\n",
    "\n",
    "In technical terms, our cost function for linear regression is the sum of residual squares. When we fit a model we want to minimize the cost function, so that our model fits as closely as possible.\n",
    "\n",
    "The cost function of linear regression is relatively straightforward and can be minimized with linear algebra. More complicated models have more complicated cost functions, often these cannot be exactly minimized. \n",
    "\n",
    "L1 and L2 norms are ways of altering our cost function in linear regression in order to incorporate a penalty for large/non-zero coeefficients. Note: Beta is a vector of all betas. L1 is a penalziation based on the absolute value, where L2 is based on squaring\n",
    "\n",
    "We can add a term to our cost function, to represent this:\n",
    "\n",
    "$$ \\text{L1: } Cost = \\sum\\limits_{i=1}^{n}(y_i - \\hat{y})^2 + \\alpha(|\\beta|)$$\n",
    "$$ \\text{L2: } Cost = \\sum\\limits_{i=1}^{n}(y_i - \\hat{y})^2 + \\alpha(\\beta^2)$$\n",
    "\n",
    "L2 regularization is when we penalize coefficients by their square, (i.e. the exponent on $\\beta$ is 2). L1 regularization is when we penalize the coefficients by their absolute value, (i.e. the exponent on $\\beta$ is 1).\n",
    "\n",
    "L1 is also called Lasso regression. L2 is also called Ridge regression.\n",
    "\n",
    "L1 will set $\\beta$ values to 0 more efficiently than L2, but L2 is normally easier to compute. In general, it would be expected to compute both and compare the model performance.\n",
    "\n",
    "Ridge and Lasso regression are both implemented in statsmodels as well as in scikit-learn. We can perform these penalized regressions using statsmodels' *fit_regularized* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain model results:\n",
      "[2.23784102 2.7448505 ]\n",
      "R2: 0.4087\n",
      "L1 model results:\n",
      "[1.20658663 1.62346059]\n",
      "R2: 0.2813\n",
      "L2 model results:\n",
      "[1.09874015 1.29673039]\n",
      "R2: 0.2235\n"
     ]
    }
   ],
   "source": [
    "# Because statsmodels is a tough-to-work-with package, there's actually no easy way to pull out the R2 values\n",
    "# from models after you've fit them. Here we write a function to calculate them for us:\n",
    "def calc_R2(model, y):\n",
    "    ss_resid = np.sum((model.fittedvalues - y)**2)\n",
    "    ss_total = np.sum((y - np.mean(y))**2)\n",
    "    return round(1 - ss_resid/ss_total, 4)\n",
    "\n",
    "\n",
    "# Now let's compare the parameters and R2 values for 3 different regressions fit on the same data: plain, L1, and L2\n",
    "\n",
    "plain_model = sm.OLS(y,X).fit()\n",
    "print('Plain model results:')\n",
    "print(plain_model.params)\n",
    "print(f'R2: {calc_R2(plain_model, y)}')\n",
    "\n",
    "L1_model = sm.OLS(y,X).fit_regularized(alpha = 1, L1_wt = 1)\n",
    "print('L1 model results:')\n",
    "print(L1_model.params)\n",
    "print(f'R2: {calc_R2(L1_model, y)}')\n",
    "\n",
    "L2_model = sm.OLS(y,X).fit_regularized(alpha = 1, L1_wt = 0)\n",
    "print('L2 model results:')\n",
    "print(L2_model.params)\n",
    "print(f'R2: {calc_R2(L2_model, y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we have worsened our fit, but shrunk our parameters. For a small scale model like this, lasso and ridge are somewhat overkill, but they are useful methods as our data get larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Rerun the regression we carried out on the `customer_info.csv`, using regularization. How do the values compare? Do you think this is useful on data this size?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Tests Part II\n",
    "\n",
    "When we carried out T-tests on jellybeans, we only compared them against a certain value. We also carried out two sample T-tests, where we compared two groups. What if we want to carry out T-tests to figure out if the color of any jelly bean was different from any other?\n",
    "\n",
    "In this case, we could carry out our original T-tests against each other instead of the mean, but the number of tests would increase exponentially. We had false positive (Type I) errors with 20 comparisons, let alone the problems with 20! comparisions. We could use a multiple testing correction, but the Type II error rate, with 20! Corrections to the critical P-value would likely be very large.\n",
    "\n",
    "So, what can we do to compare between multiple samples in different categories?\n",
    "\n",
    "### ANOVA\n",
    "\n",
    "ANOVA, or 'analysis of variance' is a statistical test where we are interested in comparisons between multiple groups.\n",
    "\n",
    "In it's simplest form, we are interested in the following question: Are any groups different from the other groups?\n",
    "\n",
    "$H_0$: The mean of group 1 is equal to the mean of group 2, group 3, .... group n\n",
    "\n",
    "$H_1$ There is at least one difference between groups\n",
    "\n",
    "Essentially, we want to know if we have drawn our data from the same distribution, or from a different one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFDJJREFUeJzt3X+QXWV5wPHvQxJcf6CBTWDSbOjGMVqRweAsGGHskFBaRSTiSEsFk0qYDAOVCHYEitLp2Kk4ZUQZCkwGJNCCCKhDxqHWDD9GOmOARCgCsZKCkG2AxASQX2kDefrHnsBl2c3e3XvvnnvP/X5m7txz3nvuOc/Jj2fffc573hOZiSSpuvYqOwBJUmuZ6CWp4kz0klRxJnpJqjgTvSRVnIlekirORC9JFWeil6SKM9FLUsVNLTsAgBkzZmR/f3/ZYUhSR1m/fv3vMnPmWNu1RaLv7+9n3bp1ZYchSR0lIp6oZztLN5JUcSZ6Sao4E70kVVxb1OglqSw7d+5kcHCQHTt2lB3KqHp6eujr62PatGkT+r6JXlJXGxwcZJ999qG/v5+IKDuct8hMtm3bxuDgIHPnzp3QPizdSOpqO3bsoLe3ty2TPEBE0Nvb29BvHCZ6SV2vXZP8bo3GZ6KXpIqzRi9JNS5Z85um7u/sY97f1P1NhIleqrDLH7j89eUz5p9RYiQqk6UbSSrRfffdxyGHHMKOHTt46aWX+NCHPsRDDz3U1GPYo5ekEh122GEcf/zxfO1rX+OVV17hlFNO4eCDD27qMUz0klSyCy+8kMMOO4yenh4uvfTSpu/f0o0klWz79u28+OKLvPDCCy25Q9dEL0klW758Od/4xjc4+eSTOffcc5u+f0s3klRjsodDXnfddUydOpXPf/7zvPbaaxxxxBHccccdLFq0qGnHMNFLUomWLFnCkiVLAJgyZQr33HNP049h6UaSKq6uHn1E/BZ4AXgNeDUzByJiP+AHQD/wW+DPM/PZGJqU4bvAscDLwF9l5i+bH7qkkdTeJCXB+Hr0CzNzfmYOFOvnAbdn5jzg9mId4JPAvOK1HLiiWcFKksavkRr9YuCoYvla4C7g3KL9usxMYG1ETI+IWZn5VCOBqrPUzhfSDnN9SN2s3h59Aj+LiPURsbxoO2B38i7e9y/aZwObar47WLS9SUQsj4h1EbFu69atE4tekjSmenv0R2bm5ojYH1gTEb/ew7YjTZycb2nIXAmsBBgYGHjL51Jl3PnNN5YXnl9eHOpadSX6zNxcvG+JiB8DhwPP7C7JRMQsYEux+SAwp+brfcDmJsYsVZ8/HMpT+2ffDG3w9zdm6SYi3hkR++xeBv4UeAhYDSwtNlsK3FosrwaWxJAFwPPW5yWpPPX06A8Aflw8ymoqcENm/jQi7gNuiohlwJPAicX2tzE0tHIjQ8Mrv9j0qKUqanZPUh3h61//OjNmzGDFihUAXHDBBRxwwAGcddZZTTvGmIk+Mx8DPjxC+zbg6BHaEzizKdFJUsUtW7aMz372s6xYsYJdu3Zx4403cu+99zb1GE6BoJZzqKU0uv7+fnp7e7n//vt55plnOPTQQ+nt7W3qMUz0klSy0047jVWrVvH0009z6qmnNn3/JnppMg2vw7fBiAyV74QTTuDCCy9k586d3HDDDU3fv4leKpMXYNtPCT989957bxYuXMj06dOZMmVK0/dvoldDrL9XS+2EaGfMP6PESLrLrl27WLt2LTfffHNL9m+il7rEaEnc2S7L9cgjj3DcccdxwgknMG/evJYcw0QvSSU66KCDeOyxx1p6DBO9xq22XCOp/fmEKUmqOHv0ahp7+i3SggnOrMt3F3v0klRx9uglqUazf9tph2GqJnqNyZKM1Nks3UhSia688krmz5/P/PnzmTt3LgsXLmz6MezRa1J5J630Zqeffjqnn346O3fuZNGiRZxzzjlNP4Y9eklqAytWrGDRokV8+tOfbvq+7dFLUslWrVrFE088wWWXXdaS/ZvoVRrLOBKsX7+eiy++mLvvvpu99mpNkcVEL0k1Jns45GWXXcb27dtfvwg7MDDAVVdd1dRjmOglqUTXXHNNy4/hxVhJqjh79FIFOHeN9sRErxF5N6y6SWYSEWWHMarMbOj7Jnqpk4z2jNl93zO5cVRIT08P27Zto7e3ty2TfWaybds2enp6JrwPE72krtbX18fg4CBbt24tO5RR9fT00NfXN+Hvm+ilRrRgrnhNrmnTpjF37tyyw2gpR91IUsXZo5eaxd692pSJXupQlz/34Bsr+368vEDU9uou3UTElIi4PyJ+UqzPjYh7IuLRiPhBROxdtL+tWN9YfN7fmtAlSfUYT49+BbABeHex/i3gksy8MSKuBJYBVxTvz2bm+yLipGK7v2hizGoRx85L1VRXjz4i+oBPAVcV6wEsAm4pNrkW+EyxvLhYp/j86GjHwalSB7r8uQdff0n1qrd08x3gq8CuYr0XeC4zXy3WB4HZxfJsYBNA8fnzxfaSpBKMWbqJiOOALZm5PiKO2t08wqZZx2e1+10OLAc48MAD6wpW1eXc9FLr1FOjPxI4PiKOBXoYqtF/B5geEVOLXnsfsLnYfhCYAwxGxFTgPcD24TvNzJXASoCBgYHGJnKQJtNo0xBIbWrMRJ+Z5wPnAxQ9+r/JzJMj4mbgc8CNwFLg1uIrq4v1XxSf35GNzsgjdTHr8WpUI3fGngucExEbGarBX120Xw30Fu3nAOc1FqIkqRHjumEqM+8C7iqWHwMOH2GbHcCJTYhNXcp6vdRcznUjSRVnopekinOuG6kVKjgyp/ZxhWfMP6PESDRe9uglqeJM9JJUcSZ6Sao4a/RSFTx+9xvLc52bXm9mopc0otqLr+pslm4kqeJM9JJUcZZuJI2bY+o7i4leakPOWKlmsnQjSRVnopekijPRS1LFmeglqeK8GCvVo4KzUap7mOjV1nzalNQ4SzeSVHEmekmqOEs3UpvwJim1ij16Sao4E70kVZylmy5XO6pFFeFDSDSMPXpJqjh79F3IXrzUXUz0UpVNQhnHuenbn6UbSao4E70kVZylG3UM572RJmbMHn1E9ETEvRHxnxHxcET8fdE+NyLuiYhHI+IHEbF30f62Yn1j8Xl/a09BkrQn9ZRu/hdYlJkfBuYDn4iIBcC3gEsycx7wLLCs2H4Z8Gxmvg+4pNhOklSSMRN9DnmxWJ1WvBJYBNxStF8LfKZYXlysU3x+dERE0yKWJI1LXRdjI2JKRDwAbAHWAP8NPJeZrxabDAKzi+XZwCaA4vPngd5mBi1Jql9diT4zX8vM+UAfcDjwwZE2K95H6r3n8IaIWB4R6yJi3datW+uNV5I0TuMaXpmZzwF3AQuA6RGxe9ROH7C5WB4E5gAUn78H2D7CvlZm5kBmDsycOXNi0UuSxlTPqJuZETG9WH478CfABuBO4HPFZkuBW4vl1cU6xed3ZOZbevRSIy5Z85vXX5L2rJ5x9LOAayNiCkM/GG7KzJ9ExCPAjRHxD8D9wNXF9lcD/xIRGxnqyZ/Ugrg1TiZEqXuNmegz80Hg0BHaH2OoXj+8fQdwYlOikyQ1zCkQJKniTPSSVHEmekmqOCc1kybR5c89+Kb1M6YfUlIk6ib26CWp4uzRS93Ch4Z3LRO9NJo7v1l2BFJTWLqRpIqzRy+paXxQeHuyRy9JFWePXlJL2LtvH/boJaniTPSSVHEmekmqOGv0Ui3HzquCTPQV5sNGJIGlG0mqPHv0UomGz2YptYI9ekmqOBO9JFWcpRt1vNqLzmcf8/4SI5Hakz16Sao4E70kVZyJXpIqzkQvSRXnxVhVyvC7gb04K5nope7kg8K7ioleajHvflXZTPSSM1a2nE+bKpcXYyWp4sZM9BExJyLujIgNEfFwRKwo2veLiDUR8Wjxvm/RHhFxaURsjIgHI+IjrT4JSdLo6unRvwp8JTM/CCwAzoyIg4DzgNszcx5we7EO8ElgXvFaDlzR9KglSXUbs0afmU8BTxXLL0TEBmA2sBg4qtjsWuAu4Nyi/brMTGBtREyPiFnFftRiPmxE0nDjqtFHRD9wKHAPcMDu5F28719sNhvYVPO1waJNklSCukfdRMS7gB8CX87M30fEqJuO0JYj7G85Q6UdDjzwwHrDkNThHIEz+erq0UfENIaS/PWZ+aOi+ZmImFV8PgvYUrQPAnNqvt4HbB6+z8xcmZkDmTkwc+bMicYvqVGP3/3GS5VUz6ibAK4GNmTmt2s+Wg0sLZaXArfWtC8pRt8sAJ63Pi9J5amndHMk8AXgVxHxQNH2t8BFwE0RsQx4Ejix+Ow24FhgI/Ay8MWmRiyNgw8lkeobdfMfjFx3Bzh6hO0TOLPBuKSO5rQHaidOgaDu5LQH6iJOgSBJFWeil6SKM9FLUsVZo68Apz2QtCf26CWp4kz0klRxJnpJqjhr9B3KurykepnoJb2hdmKzuR8vLw41laUbSao4E70kVZylG0ml8SEkk8NEr+7hRGbqUiZ6dY1fPLbt9eWPvbe3xEikyWWNXpIqzkQvSRVn6UbSyIY/LNxx9R3LRK9KW/Dkykk7lo8PVLsy0XcQpz2QNBHW6CWp4kz0klRxJnpJqjhr9JLagtMhtI49ekmqOHv06kpOh6BuYo9ekirORC9JFWfpRpUymXfCgnfDqjPYo5ekihsz0UfE9yJiS0Q8VNO2X0SsiYhHi/d9i/aIiEsjYmNEPBgRH2ll8JIm0eN3v/FSR6mndLMKuAy4rqbtPOD2zLwoIs4r1s8FPgnMK14fBa4o3qWWsVwj7dmYiT4zfx4R/cOaFwNHFcvXAncxlOgXA9dlZgJrI2J6RMzKzKeaFXC3cSKz1nOo5QTU9upbMH2xN08110Rr9AfsTt7F+/5F+2xgU812g0WbJKkkzb4YGyO05YgbRiyPiHURsW7r1q1NDkOStNtEE/0zETELoHjfUrQPAnNqtusDNo+0g8xcmZkDmTkwc+bMCYYhSRrLRBP9amBpsbwUuLWmfUkx+mYB8Lz1eUkq15gXYyPi+wxdeJ0REYPA3wEXATdFxDLgSeDEYvPbgGOBjcDLwBdbELMkaRzqGXXzl6N8dPQI2yZwZqNBSZKaxztjJaninOtGUltzTH3j7NFLUsXZo5dqeJesqshEL42idk6bM6YfUmIkUmNM9FIdnMhsD1o8740aZ6JvQ05kNrbJnrFS6mRejJWkijPRS1LFWbppA5ZqJLWSPXpJqjh79CWxF9/+Nj33yuvLc6a/vcRIpMbYo5ekirNHr44xGUMqV++1seXHqDSfJduWTPRSHSzjTIA3UrUNSzeSVHH26CV1pNoyDljK2RMTvdpaO051YBlHncZEL6kSvFA7OhN9i9WOlz/7mPeXGImkbmWin0TeJFWfdizXSJ3MRK+u59j5Seawy0lnopfUerXJXZPORK+uZC9e3cREr7bQqdMbONSyPTkC581M9CqNF101GUz6JvqWcHRN+7BE0+a8MDspTPRSk1jGaX/d2rs30TfAnnv7aZcefG3Sr+UPAJXBRK9JZV1emnwtSfQR8Qngu8AU4KrMvKgVx1FnaEVyb5eeu5potLH2Lardj1bGqWJ5p+mJPiKmAP8MHAMMAvdFxOrMfKTZx5oszlejZhle0rGUU4d6b7Zq4AfC8CmPq6YVPfrDgY2Z+RhARNwILAbaPtHXU3O3Ll8fe/H18QJue6tK774ViX42sKlmfRD4aAuOs0fDE3JtT7wbk3Vt4l174PIJf7dRoyXr43e9b1zbV9FoF3BrjfbDwB8Y1NfzH63XX8cwz3p6/aOVgIZ/NtkiM5u7w4gTgT/LzNOK9S8Ah2fml4ZttxzYnXE+APxXUwNpvhnA78oOogmqch7gubSrqpxLJ5zHH2bmzLE2akWPfhCYU7PeB2wevlFmrgQ6ZghGRKzLzIGy42hUVc4DPJd2VZVzqcp5QGseDn4fMC8i5kbE3sBJwOoWHEeSVIem9+gz89WI+Gvg3xkaXvm9zHy42ceRJNWnJePoM/M24LZW7LtEHVNmGkNVzgM8l3ZVlXOpynk0/2KsJKm9tKJGL0lqIyb6PYiIORFxZ0RsiIiHI2JF2TE1KiKmRMT9EfGTsmNpRERMj4hbIuLXxd/Px8qOaSIi4uzi39ZDEfH9iOgpO6Z6RcT3ImJLRDxU07ZfRKyJiEeL933LjLFeo5zLPxX/vh6MiB9HxPQyY2yEiX7PXgW+kpkfBBYAZ0bEQSXH1KgVwIayg2iC7wI/zcw/Aj5MB55TRMwGzgIGMvNghgYvnFRuVOOyCvjEsLbzgNszcx5we7HeCVbx1nNZAxycmYcAvwHOn+ygmsVEvweZ+VRm/rJYfoGhZDK73KgmLiL6gE8BV5UdSyMi4t3AHwNXA2Tm/2Xmc+VGNWFTgbdHxFTgHYxwz0m7ysyfA9uHNS8Gri2WrwU+M6lBTdBI55KZP8vMV4vVtQzdE9SRTPR1ioh+4FDgnnIjach3gK8Cu8oOpEHvBbYC1xRlqKsi4p1lBzVemfk/wMXAk8BTwPOZ+bNyo2rYAZn5FAx1lID9S46nWU4F/q3sICbKRF+HiHgX8EPgy5n5+7LjmYiIOA7Ykpnry46lCaYCHwGuyMxDgZfonBLB64r69WJgLvAHwDsj4pRyo9JwEXEBQ2Xc68uOZaJM9GOIiGkMJfnrM/NHZcfTgCOB4yPit8CNwKKI+NdyQ5qwQWAwM3f/dnULQ4m/0/wJ8Hhmbs3MncCPgCNKjqlRz0TELIDifUvJ8TQkIpYCxwEnZwePRTfR70FEBEN14A2Z+e2y42lEZp6fmX2Z2c/QBb87MrMje4+Z+TSwKSI+UDQdTQdMgz2CJ4EFEfGO4t/a0XTgReVhVgNLi+WlwK0lxtKQ4gFK5wLHZ+bLZcfTCBP9nh0JfIGh3u8DxevYsoMSAF8Cro+IB4H5wD+WHM+4Fb+R3AL8EvgVQ/8fO+ZuzIj4PvAL4AMRMRgRy4CLgGMi4lGGHj7UEU+XG+VcLgP2AdYU//evLDXIBnhnrCRVnD16Sao4E70kVZyJXpIqzkQvSRVnopekijPRS1LFmeglqeJM9JJUcf8PnqS9/uLMIwcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.random.normal(loc = 5, scale = 1, size = 10000)\n",
    "y = np.random.normal(loc = 8, scale = 1, size = 10000)\n",
    "z = np.random.normal(loc = 9, scale = 1, size = 10000)\n",
    "\n",
    "bins = np.linspace(1, 13, 100)\n",
    "plt.hist(x, bins, alpha=0.5, label='x')\n",
    "plt.hist(y, bins, alpha=0.5, label='y')\n",
    "plt.hist(z, bins, alpha=0.5, label='z')\n",
    "\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circadian Rhythm Data \n",
    "\n",
    "In a famous experiment, [two researchers tried to replicate a finding](http://science.sciencemag.org/content/297/5581/571.full) that shining light into the back of subjects knees decreased jetlag. We have three categories of treatment: light shined into the eyes, light shined into the back of the knees, and a control, no light treatment. The dependent variable is `shift` a measure of the change in circadian rhythm of the subjects.\n",
    "\n",
    "The data are `jetlag.csv` from [here](https://drive.google.com/file/d/1_q7fc5bZteKOKmvBL2fGwDYOJ00Il9Fm/view?usp=sharing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>control</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>control</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>control</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>control</td>\n",
       "      <td>-0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>control</td>\n",
       "      <td>-0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  treatment  shift\n",
       "0   control   0.36\n",
       "1   control   0.53\n",
       "2   control   0.20\n",
       "3   control  -0.37\n",
       "4   control  -0.60"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jetlag = pd.read_csv('Data/jetlag.csv')\n",
    "jetlag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "sns.violinplot(x = 'treatment', y = 'shift', data = jetlag);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compare the difference between the treatments, to see if they come from the same distribution ie., whether shining a light had an effect in any of the treatments.\n",
    "\n",
    "The way to do this is to calculate the mean for each group, as well as the overall mean of responses. We want the mean and variance of each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">shift</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>control</th>\n",
       "      <td>-0.308750</td>\n",
       "      <td>0.381384</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyes</th>\n",
       "      <td>-1.551429</td>\n",
       "      <td>0.498881</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knee</th>\n",
       "      <td>-0.335714</td>\n",
       "      <td>0.625395</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              shift                \n",
       "               mean       var count\n",
       "treatment                          \n",
       "control   -0.308750  0.381384     8\n",
       "eyes      -1.551429  0.498881     7\n",
       "knee      -0.335714  0.625395     7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agglag = jetlag.groupby('treatment').aggregate({'shift':['mean', 'var', 'count']})\n",
    "agglag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shift    0.792373\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jetlag.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to take the sum of all the variances, times the number of samples - 1:\n",
    "\n",
    "$$ MS_{error} = \\frac{\\sum s_i^2(n_i-1)}{N - k}$$\n",
    "\n",
    "Here we have the Mean Squared error across the groups: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49554445488721804"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mserror = np.sum(agglag['shift']['var'] * (agglag['shift']['count'] - 1))/(22-3)\n",
    "mserror"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a measure of our error mean square. We now want to compare this to the overall error.\n",
    "\n",
    "$$ MS_{groups} = \\frac{\\sum n_i (\\bar{Y_i} - \\bar{Y})^2}{k - 1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7127272727272728\n",
      "3.6122458603896113\n"
     ]
    }
   ],
   "source": [
    "avgshift = np.mean(jetlag['shift'])\n",
    "print(avgshift)\n",
    "msgroup = np.sum((agglag['shift']['count'] * (agglag['shift']['mean'] - avgshift)**2)/(3-1))\n",
    "print(msgroup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that we have our mean square for our groups, and our mean square error, we can calculate our F statistic:\n",
    "\n",
    "$$ F = \\frac{MS_{groups}}{MS_{error}} $$\n",
    "\n",
    "In other words:\n",
    "\n",
    "$$ F = \\frac{variation of means_{between groups}}{variation of means_{within groups}} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.289448655442486"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fstat = msgroup/mserror\n",
    "fstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intuition for this test is that if the groups are all the same, then a subgrouping of the data will have the same variance as the total data. In this case, F will be 1. If there is a difference, then the variances will be different, and thus F will be larger than one.\n",
    "\n",
    "The F-statistic comes from the F-distribution, similar to a t distribution. We need to know the degrees of freedom of the $MS_{groups}$ (number of groups -1) and the $MS_{error}$ (nobs - ngroups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004472271090001145"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "dof_ms_groups = 2\n",
    "dof_ms_error = 22-3\n",
    "\n",
    "p_value = 1 - stats.f.cdf(fstat, dof_ms_groups, dof_ms_error)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we intepret the p-value, in relation to our null and alternate hypotheses?\n",
    "\n",
    "Our P-value is less than the critical value of 0.05 (our model has incorporated the way we carried out the testing, we don't need to worry about the multiple comparisions). \n",
    "\n",
    "So, we can reject the null hypothesis that our data is from the same distribution and can say that our data came from different distributions. There is an effect of our treatments. Which treatment in particular? After a small interlude we will discuss what we have actually done. \n",
    "\n",
    "Now that we have done it the hard way, is this built in anywhere?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>mean_sq</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>treatment</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.224492</td>\n",
       "      <td>3.612246</td>\n",
       "      <td>7.289449</td>\n",
       "      <td>0.004472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>19.0</td>\n",
       "      <td>9.415345</td>\n",
       "      <td>0.495544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             df    sum_sq   mean_sq         F    PR(>F)\n",
       "treatment   2.0  7.224492  3.612246  7.289449  0.004472\n",
       "Residual   19.0  9.415345  0.495544       NaN       NaN"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "jetlag_lm = ols('shift ~ treatment', data=jetlag).fit()\n",
    "anova_lm(jetlag_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>shift</td>      <th>  R-squared:         </th> <td>   0.434</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   7.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 29 Jan 2019</td> <th>  Prob (F-statistic):</th>  <td>0.00447</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:18:09</td>     <th>  Log-Likelihood:    </th> <td> -21.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    22</td>      <th>  AIC:               </th> <td>   49.76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    19</td>      <th>  BIC:               </th> <td>   53.03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>   -0.3087</td> <td>    0.249</td> <td>   -1.241</td> <td> 0.230</td> <td>   -0.830</td> <td>    0.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treatment[T.eyes]</th> <td>   -1.2427</td> <td>    0.364</td> <td>   -3.411</td> <td> 0.003</td> <td>   -2.005</td> <td>   -0.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treatment[T.knee]</th> <td>   -0.0270</td> <td>    0.364</td> <td>   -0.074</td> <td> 0.942</td> <td>   -0.790</td> <td>    0.736</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.945</td> <th>  Durbin-Watson:     </th> <td>   1.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.623</td> <th>  Jarque-Bera (JB):  </th> <td>   0.919</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.355</td> <th>  Prob(JB):          </th> <td>   0.632</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.293</td> <th>  Cond. No.          </th> <td>    3.60</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  shift   R-squared:                       0.434\n",
       "Model:                            OLS   Adj. R-squared:                  0.375\n",
       "Method:                 Least Squares   F-statistic:                     7.289\n",
       "Date:                Tue, 29 Jan 2019   Prob (F-statistic):            0.00447\n",
       "Time:                        14:18:09   Log-Likelihood:                -21.881\n",
       "No. Observations:                  22   AIC:                             49.76\n",
       "Df Residuals:                      19   BIC:                             53.03\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "Intercept            -0.3087      0.249     -1.241      0.230      -0.830       0.212\n",
       "treatment[T.eyes]    -1.2427      0.364     -3.411      0.003      -2.005      -0.480\n",
       "treatment[T.knee]    -0.0270      0.364     -0.074      0.942      -0.790       0.736\n",
       "==============================================================================\n",
       "Omnibus:                        0.945   Durbin-Watson:                   1.204\n",
       "Prob(Omnibus):                  0.623   Jarque-Bera (JB):                0.919\n",
       "Skew:                          -0.355   Prob(JB):                        0.632\n",
       "Kurtosis:                       2.293   Cond. No.                         3.60\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jetlag_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that this type of analysis is a special case of linear regression!\n",
    "\n",
    "We can now interpret the `F-statistic` and `Prob (F-statistic)` in the summary table. It tells us how much better than no model our model is. The coefficients of the model give us the intercept (in this case the mean of the control treatment), and the difference in means between the groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">shift</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>control</th>\n",
       "      <td>-0.308750</td>\n",
       "      <td>0.381384</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyes</th>\n",
       "      <td>-1.551429</td>\n",
       "      <td>0.498881</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knee</th>\n",
       "      <td>-0.335714</td>\n",
       "      <td>0.625395</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              shift                \n",
       "               mean       var count\n",
       "treatment                          \n",
       "control   -0.308750  0.381384     8\n",
       "eyes      -1.551429  0.498881     7\n",
       "knee      -0.335714  0.625395     7"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.violinplot(x = 'treatment', y = 'shift', data = jetlag);\n",
    "agglag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced ANOVA\n",
    "\n",
    "We have run a one-way, Type I ANOVA. \n",
    "\n",
    "ANOVAs can be run on data with interactions. We might have a two way treatment, such as giving the subjects a drug in addition to the light treatment. We can then test for any interaction between drug and light, as well as the individual drug and light effects. This is a two way ANOVA. This is equivalent to a linear model with an interaction term.\n",
    "\n",
    "Type II and Type III ANOVAs involve random and mixed effects, which we will skip for now. \n",
    "\n",
    "### A Priori and Post Hoc Testing\n",
    "\n",
    "After our ANOVA on jetlag, we know that at least one mean is different from at least one of the others.\n",
    "\n",
    "We can carry out tests to determine which one is different.\n",
    "\n",
    "As we discussed, if we have a large number of tests we will eventually get false positives (Type I errors). We saw Brian Wansink had carried out an experiment, then a large number of posthoc tests, effectively p-hacking the answer.\n",
    "\n",
    "So if we have a planned comparision we are fine running a t-test. If we have other comparisons, we can make them once our ANOVA has shown a significant p-value, but we need to make sure we use a post-hoc correction like the Bonferroni correction.\n",
    "\n",
    "In our example, were trying to determine whether previous studies showed that shining a light to the back of the knee was as beneficial as shining a light to the eyes. Therefore,I think we are justified in running a T-test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=3.033500238074507, pvalue=0.010398726258732876)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(jetlag['shift'][jetlag['treatment'] == 'knee'], jetlag['shift'][jetlag['treatment'] == 'eyes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a significant difference! Additionally, we could probably say we planned the knee vs control. Maybe there was an effect and we didn't care if it was as big as the eye effect. Once we have a larger number of a priori tests we need to calculate a corrected significance value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.07412621710300148, pvalue=0.9420384259725368)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(jetlag['shift'][jetlag['treatment'] == 'knee'], jetlag['shift'][jetlag['treatment'] == 'control'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it doesn't matter, as it is non-significant either way. You might be a little worried now, how can we tell what was preplanned and what wasn't? Are we trusting researchers or not? How does planning something beforehand influence what a p-value means?\n",
    "\n",
    "One of the most common post-hoc tests is Tukey's Honestly Significant Difference test. This calculates all pairwise comparisions based on data and groups. It also corrects for multiple comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Multiple Comparison of Means - Tukey HSD,FWER=0.05</caption>\n",
       "<tr>\n",
       "  <th>group1</th>  <th>group2</th> <th>meandiff</th>  <th>lower</th>   <th>upper</th>  <th>reject</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>control</td>  <td>eyes</td>   <td>-1.2427</td> <td>-2.168</td>  <td>-0.3173</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>control</td>  <td>knee</td>   <td>-0.027</td>  <td>-0.9523</td> <td>0.8984</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>eyes</td>    <td>knee</td>   <td>1.2157</td>   <td>0.26</td>   <td>2.1714</td>   <td>True</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats import multicomp\n",
    "\n",
    "multicomp.pairwise_tukeyhsd(jetlag['shift'], jetlag['treatment']).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "For our jellybean data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "from matplotlib import colors\n",
    "\n",
    "mycolors = np.random.choice(list(colors.CSS4_COLORS.keys()), 40, replace = True)\n",
    "mydict = {}\n",
    "np.random.seed(2345)\n",
    "for i in mycolors:\n",
    "    if i == 'peachpuff':\n",
    "        mydict[i] = np.random.normal(loc = 1, scale = 1, size = 30)\n",
    "    else:\n",
    "        mydict[i] = np.random.normal(loc = 0, scale = 1, size = 30)\n",
    "\n",
    "data = pd.DataFrame(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forestgreen</th>\n",
       "      <th>darkturquoise</th>\n",
       "      <th>gray</th>\n",
       "      <th>plum</th>\n",
       "      <th>wheat</th>\n",
       "      <th>darkgoldenrod</th>\n",
       "      <th>darkorange</th>\n",
       "      <th>salmon</th>\n",
       "      <th>darkgrey</th>\n",
       "      <th>purple</th>\n",
       "      <th>...</th>\n",
       "      <th>pink</th>\n",
       "      <th>orchid</th>\n",
       "      <th>chartreuse</th>\n",
       "      <th>indigo</th>\n",
       "      <th>lightyellow</th>\n",
       "      <th>mediumaquamarine</th>\n",
       "      <th>cadetblue</th>\n",
       "      <th>midnightblue</th>\n",
       "      <th>peachpuff</th>\n",
       "      <th>mediumorchid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.951299</td>\n",
       "      <td>-0.182431</td>\n",
       "      <td>2.202115</td>\n",
       "      <td>-0.109486</td>\n",
       "      <td>0.667898</td>\n",
       "      <td>-1.748654</td>\n",
       "      <td>-1.859181</td>\n",
       "      <td>0.349829</td>\n",
       "      <td>-1.402316</td>\n",
       "      <td>1.250608</td>\n",
       "      <td>...</td>\n",
       "      <td>2.035900</td>\n",
       "      <td>1.062332</td>\n",
       "      <td>0.590726</td>\n",
       "      <td>-1.142776</td>\n",
       "      <td>-1.743171</td>\n",
       "      <td>0.354484</td>\n",
       "      <td>0.193544</td>\n",
       "      <td>0.046710</td>\n",
       "      <td>-0.562896</td>\n",
       "      <td>1.568013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.768772</td>\n",
       "      <td>1.636892</td>\n",
       "      <td>-1.518310</td>\n",
       "      <td>-1.715815</td>\n",
       "      <td>0.217430</td>\n",
       "      <td>-2.142039</td>\n",
       "      <td>1.005521</td>\n",
       "      <td>-0.946563</td>\n",
       "      <td>-0.968701</td>\n",
       "      <td>-1.576459</td>\n",
       "      <td>...</td>\n",
       "      <td>1.192312</td>\n",
       "      <td>-0.786073</td>\n",
       "      <td>0.509321</td>\n",
       "      <td>0.195001</td>\n",
       "      <td>-1.035181</td>\n",
       "      <td>0.302980</td>\n",
       "      <td>0.005098</td>\n",
       "      <td>0.753012</td>\n",
       "      <td>2.460081</td>\n",
       "      <td>0.471475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.141827</td>\n",
       "      <td>-0.235464</td>\n",
       "      <td>-2.162442</td>\n",
       "      <td>-0.675781</td>\n",
       "      <td>1.533460</td>\n",
       "      <td>0.764554</td>\n",
       "      <td>2.132363</td>\n",
       "      <td>-0.053112</td>\n",
       "      <td>0.474980</td>\n",
       "      <td>0.190921</td>\n",
       "      <td>...</td>\n",
       "      <td>1.138646</td>\n",
       "      <td>2.625113</td>\n",
       "      <td>-0.232450</td>\n",
       "      <td>0.484568</td>\n",
       "      <td>0.539180</td>\n",
       "      <td>-0.261170</td>\n",
       "      <td>-0.265615</td>\n",
       "      <td>-1.764482</td>\n",
       "      <td>0.549692</td>\n",
       "      <td>3.024361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.710755</td>\n",
       "      <td>-1.864630</td>\n",
       "      <td>0.133611</td>\n",
       "      <td>0.152842</td>\n",
       "      <td>-0.118619</td>\n",
       "      <td>0.935855</td>\n",
       "      <td>2.247562</td>\n",
       "      <td>-0.768636</td>\n",
       "      <td>-0.886693</td>\n",
       "      <td>-1.494557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231384</td>\n",
       "      <td>-0.083275</td>\n",
       "      <td>0.512956</td>\n",
       "      <td>0.840618</td>\n",
       "      <td>-0.448363</td>\n",
       "      <td>0.987353</td>\n",
       "      <td>1.161321</td>\n",
       "      <td>0.269758</td>\n",
       "      <td>1.423926</td>\n",
       "      <td>0.188078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.510951</td>\n",
       "      <td>2.784603</td>\n",
       "      <td>0.802777</td>\n",
       "      <td>-0.220339</td>\n",
       "      <td>2.275396</td>\n",
       "      <td>-0.897440</td>\n",
       "      <td>0.830540</td>\n",
       "      <td>1.012924</td>\n",
       "      <td>0.528602</td>\n",
       "      <td>-1.277230</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.001829</td>\n",
       "      <td>-0.562558</td>\n",
       "      <td>-1.792183</td>\n",
       "      <td>-0.319206</td>\n",
       "      <td>-2.604699</td>\n",
       "      <td>-0.149449</td>\n",
       "      <td>-0.295196</td>\n",
       "      <td>0.193344</td>\n",
       "      <td>0.631053</td>\n",
       "      <td>0.946132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   forestgreen  darkturquoise      gray      plum     wheat  darkgoldenrod  \\\n",
       "0    -0.951299      -0.182431  2.202115 -0.109486  0.667898      -1.748654   \n",
       "1     1.768772       1.636892 -1.518310 -1.715815  0.217430      -2.142039   \n",
       "2    -1.141827      -0.235464 -2.162442 -0.675781  1.533460       0.764554   \n",
       "3     0.710755      -1.864630  0.133611  0.152842 -0.118619       0.935855   \n",
       "4     0.510951       2.784603  0.802777 -0.220339  2.275396      -0.897440   \n",
       "\n",
       "   darkorange    salmon  darkgrey    purple      ...           pink    orchid  \\\n",
       "0   -1.859181  0.349829 -1.402316  1.250608      ...       2.035900  1.062332   \n",
       "1    1.005521 -0.946563 -0.968701 -1.576459      ...       1.192312 -0.786073   \n",
       "2    2.132363 -0.053112  0.474980  0.190921      ...       1.138646  2.625113   \n",
       "3    2.247562 -0.768636 -0.886693 -1.494557      ...       0.231384 -0.083275   \n",
       "4    0.830540  1.012924  0.528602 -1.277230      ...      -1.001829 -0.562558   \n",
       "\n",
       "   chartreuse    indigo  lightyellow  mediumaquamarine  cadetblue  \\\n",
       "0    0.590726 -1.142776    -1.743171          0.354484   0.193544   \n",
       "1    0.509321  0.195001    -1.035181          0.302980   0.005098   \n",
       "2   -0.232450  0.484568     0.539180         -0.261170  -0.265615   \n",
       "3    0.512956  0.840618    -0.448363          0.987353   1.161321   \n",
       "4   -1.792183 -0.319206    -2.604699         -0.149449  -0.295196   \n",
       "\n",
       "   midnightblue  peachpuff  mediumorchid  \n",
       "0      0.046710  -0.562896      1.568013  \n",
       "1      0.753012   2.460081      0.471475  \n",
       "2     -1.764482   0.549692      3.024361  \n",
       "3      0.269758   1.423926      0.188078  \n",
       "4      0.193344   0.631053      0.946132  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use `stack` method as well as `reset_index` to get the dataframe into a suitable format for analysis. We want `long` data, with a column for the color, and a column for the response, similar to the jetlag data. Use these methods for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forestgreen</td>\n",
       "      <td>-0.951299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>darkturquoise</td>\n",
       "      <td>-0.182431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gray</td>\n",
       "      <td>2.202115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plum</td>\n",
       "      <td>-0.109486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wheat</td>\n",
       "      <td>0.667898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>darkgoldenrod</td>\n",
       "      <td>-1.748654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>darkorange</td>\n",
       "      <td>-1.859181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>salmon</td>\n",
       "      <td>0.349829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>darkgrey</td>\n",
       "      <td>-1.402316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>purple</td>\n",
       "      <td>1.250608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>red</td>\n",
       "      <td>0.611923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>papayawhip</td>\n",
       "      <td>-1.588129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lightcyan</td>\n",
       "      <td>-0.356026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lightsteelblue</td>\n",
       "      <td>1.748580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>seashell</td>\n",
       "      <td>-0.194307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ghostwhite</td>\n",
       "      <td>0.209138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lightseagreen</td>\n",
       "      <td>-0.526208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>darkslategrey</td>\n",
       "      <td>0.082912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>darkseagreen</td>\n",
       "      <td>-1.682253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>thistle</td>\n",
       "      <td>-0.848648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sienna</td>\n",
       "      <td>-0.001317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lightsalmon</td>\n",
       "      <td>-1.267400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aquamarine</td>\n",
       "      <td>1.013351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>aqua</td>\n",
       "      <td>1.656640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>crimson</td>\n",
       "      <td>-0.930425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tomato</td>\n",
       "      <td>0.511075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pink</td>\n",
       "      <td>2.035900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>orchid</td>\n",
       "      <td>1.062332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>chartreuse</td>\n",
       "      <td>0.590726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>indigo</td>\n",
       "      <td>-1.142776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>darkorange</td>\n",
       "      <td>-0.644176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>salmon</td>\n",
       "      <td>0.788901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>darkgrey</td>\n",
       "      <td>0.457492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>purple</td>\n",
       "      <td>0.528853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>red</td>\n",
       "      <td>-0.192060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>papayawhip</td>\n",
       "      <td>0.733578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>lightcyan</td>\n",
       "      <td>-0.383167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>lightsteelblue</td>\n",
       "      <td>-1.202799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>seashell</td>\n",
       "      <td>-1.618316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>ghostwhite</td>\n",
       "      <td>0.401078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>lightseagreen</td>\n",
       "      <td>-0.465003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>darkslategrey</td>\n",
       "      <td>-1.632631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>darkseagreen</td>\n",
       "      <td>0.491848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>thistle</td>\n",
       "      <td>0.767268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>sienna</td>\n",
       "      <td>-0.876651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>lightsalmon</td>\n",
       "      <td>0.972343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>aquamarine</td>\n",
       "      <td>-1.456906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>aqua</td>\n",
       "      <td>0.733531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>crimson</td>\n",
       "      <td>0.298936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>tomato</td>\n",
       "      <td>1.302440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>pink</td>\n",
       "      <td>0.885511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>orchid</td>\n",
       "      <td>-1.141627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>chartreuse</td>\n",
       "      <td>1.222053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>indigo</td>\n",
       "      <td>-0.986519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>lightyellow</td>\n",
       "      <td>0.600408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>mediumaquamarine</td>\n",
       "      <td>-0.017652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>cadetblue</td>\n",
       "      <td>-1.815910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>midnightblue</td>\n",
       "      <td>1.134280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>peachpuff</td>\n",
       "      <td>-0.103175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>mediumorchid</td>\n",
       "      <td>0.810453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1080 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               level_1         0\n",
       "0          forestgreen -0.951299\n",
       "1        darkturquoise -0.182431\n",
       "2                 gray  2.202115\n",
       "3                 plum -0.109486\n",
       "4                wheat  0.667898\n",
       "5        darkgoldenrod -1.748654\n",
       "6           darkorange -1.859181\n",
       "7               salmon  0.349829\n",
       "8             darkgrey -1.402316\n",
       "9               purple  1.250608\n",
       "10                 red  0.611923\n",
       "11          papayawhip -1.588129\n",
       "12           lightcyan -0.356026\n",
       "13      lightsteelblue  1.748580\n",
       "14            seashell -0.194307\n",
       "15          ghostwhite  0.209138\n",
       "16       lightseagreen -0.526208\n",
       "17       darkslategrey  0.082912\n",
       "18        darkseagreen -1.682253\n",
       "19             thistle -0.848648\n",
       "20              sienna -0.001317\n",
       "21         lightsalmon -1.267400\n",
       "22          aquamarine  1.013351\n",
       "23                aqua  1.656640\n",
       "24             crimson -0.930425\n",
       "25              tomato  0.511075\n",
       "26                pink  2.035900\n",
       "27              orchid  1.062332\n",
       "28          chartreuse  0.590726\n",
       "29              indigo -1.142776\n",
       "...                ...       ...\n",
       "1050        darkorange -0.644176\n",
       "1051            salmon  0.788901\n",
       "1052          darkgrey  0.457492\n",
       "1053            purple  0.528853\n",
       "1054               red -0.192060\n",
       "1055        papayawhip  0.733578\n",
       "1056         lightcyan -0.383167\n",
       "1057    lightsteelblue -1.202799\n",
       "1058          seashell -1.618316\n",
       "1059        ghostwhite  0.401078\n",
       "1060     lightseagreen -0.465003\n",
       "1061     darkslategrey -1.632631\n",
       "1062      darkseagreen  0.491848\n",
       "1063           thistle  0.767268\n",
       "1064            sienna -0.876651\n",
       "1065       lightsalmon  0.972343\n",
       "1066        aquamarine -1.456906\n",
       "1067              aqua  0.733531\n",
       "1068           crimson  0.298936\n",
       "1069            tomato  1.302440\n",
       "1070              pink  0.885511\n",
       "1071            orchid -1.141627\n",
       "1072        chartreuse  1.222053\n",
       "1073            indigo -0.986519\n",
       "1074       lightyellow  0.600408\n",
       "1075  mediumaquamarine -0.017652\n",
       "1076         cadetblue -1.815910\n",
       "1077      midnightblue  1.134280\n",
       "1078         peachpuff -0.103175\n",
       "1079      mediumorchid  0.810453\n",
       "\n",
       "[1080 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Stacks\n",
    "data_stack = data.stack()\n",
    "\n",
    "data_stack_long = pd.DataFrame(data_stack).reset_index() #but this stacks by index into a Series, which we dont want\n",
    "data_stack_long = data_stack_long.drop(['level_0'], axis = 1) #this gets rid of the series\n",
    "display(data_stack_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1080 entries, 0 to 1079\n",
      "Data columns (total 2 columns):\n",
      "Colour    1080 non-null object\n",
      "Acne      1080 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 17.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data_stack_long.columns = ['Colour','Acne']\n",
    "data_stack_long.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetlag.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Carry out an ANOVA on the data, to see if there is a difference between any of the jellybeans effects on acne.\n",
    "3. Do we have any planned comparisons? What if I told you that peachpuff cured acne? What if it was a published paper? \n",
    "4. Run a planned comparison T-test between peachpuff and forestgreen. Can we think of a more sensibly planned comparison?\n",
    "5. Assume we got a significant value in our ANOVA so we can do a Tukey-HSD on the results. Do we have any significant comparisions?\n",
    "6. Is this a sensible test setup? Should we be comparing to a control, or to other colors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>mean_sq</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Colour</th>\n",
       "      <td>35.0</td>\n",
       "      <td>45.263711</td>\n",
       "      <td>1.293249</td>\n",
       "      <td>1.380399</td>\n",
       "      <td>0.070857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>1044.0</td>\n",
       "      <td>978.088175</td>\n",
       "      <td>0.936866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              df      sum_sq   mean_sq         F    PR(>F)\n",
       "Colour      35.0   45.263711  1.293249  1.380399  0.070857\n",
       "Residual  1044.0  978.088175  0.936866       NaN       NaN"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 ANOVA\n",
    "\n",
    "jelly_lm = ols('Acne ~ Colour', data=data_stack_long).fit()\n",
    "anova_lm(jelly_lm)\n",
    "#we see that we cannot reject, however its pretty close so we continue to investigate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "#Planned comparisons are comaprisons you wanted to look at ahead of time based on suspicions - i.e if you thought crimson was better but wanted to investigate\n",
    "#No we did not have any planned comaprison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=2.631969054616263, pvalue=0.010859358854235576)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. Run a planned comaprison (T-test)between peachpuff and forestgreen\n",
    "from scipy import stats\n",
    "\n",
    "planned_comp = stats.ttest_ind(data_stack_long['Acne'][data_stack_long['Colour']=='peachpuff'],\\\n",
    "                              data_stack_long['Acne'][data_stack_long['Colour']=='forestgreen'])\n",
    "planned_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indcates that the difference between these two is statistically significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggjelly = data_stack_long.groupby('Colour').aggregate({'Acne':['mean', 'var', 'count']})\n",
    "aggjelly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import multicomp\n",
    "\n",
    "\n",
    "\n",
    "multi_comp = multicomp.pairwise_tukeyhsd(data_stack_long['Acne'], data_stack_long['Colour']).summary()\n",
    "multi_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group1</th>\n",
       "      <th>group2</th>\n",
       "      <th>meandiff</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>reject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aqua</td>\n",
       "      <td>aquamarine</td>\n",
       "      <td>-0.0189</td>\n",
       "      <td>-0.9808</td>\n",
       "      <td>0.9429</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aqua</td>\n",
       "      <td>cadetblue</td>\n",
       "      <td>-0.1328</td>\n",
       "      <td>-1.0946</td>\n",
       "      <td>0.8291</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aqua</td>\n",
       "      <td>chartreuse</td>\n",
       "      <td>0.0955</td>\n",
       "      <td>-0.8663</td>\n",
       "      <td>1.0573</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aqua</td>\n",
       "      <td>crimson</td>\n",
       "      <td>-0.1176</td>\n",
       "      <td>-1.0794</td>\n",
       "      <td>0.8443</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aqua</td>\n",
       "      <td>darkgoldenrod</td>\n",
       "      <td>-0.3405</td>\n",
       "      <td>-1.3023</td>\n",
       "      <td>0.6214</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group1         group2  meandiff   lower   upper  reject\n",
       "0   aqua     aquamarine   -0.0189 -0.9808  0.9429   False\n",
       "1   aqua      cadetblue   -0.1328 -1.0946  0.8291   False\n",
       "2   aqua     chartreuse    0.0955 -0.8663  1.0573   False\n",
       "3   aqua        crimson   -0.1176 -1.0794  0.8443   False\n",
       "4   aqua  darkgoldenrod   -0.3405 -1.3023  0.6214   False"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(data=multi_comp.data[1:], columns=multi_comp.data[0])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group1</th>\n",
       "      <th>group2</th>\n",
       "      <th>meandiff</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>reject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>peachpuff</td>\n",
       "      <td>plum</td>\n",
       "      <td>-1.0642</td>\n",
       "      <td>-2.026</td>\n",
       "      <td>-0.1023</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        group1 group2  meandiff  lower   upper  reject\n",
       "576  peachpuff   plum   -1.0642 -2.026 -0.1023    True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['reject']==True]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
